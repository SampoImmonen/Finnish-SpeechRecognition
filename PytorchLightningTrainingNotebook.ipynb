{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc1e7a5",
   "metadata": {},
   "source": [
    "# PytorchLightning version of training Notebook\n",
    "- easy support for multiple GPUs\n",
    "- easy support for fp16 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe093d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set contains 15920 Samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>Mitä nyt tekisimme?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>Äänestämme tämän vuoksi toisin kuin maataloude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>Rupeatko remmiin, vai et?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>Äänestin näin ollen mietinnön puolesta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>Kiitos, että tulitte ja opetitte meille viisau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "1  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "2  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "3  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "4  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "\n",
       "                                            sentence  \n",
       "0                                Mitä nyt tekisimme?  \n",
       "1  Äänestämme tämän vuoksi toisin kuin maataloude...  \n",
       "2                          Rupeatko remmiin, vai et?  \n",
       "3            Äänestin näin ollen mietinnön puolesta.  \n",
       "4  Kiitos, että tulitte ja opetitte meille viisau...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "import pandas as pd\n",
    "\n",
    "#Set all sources of data\n",
    "commonvoice = \"data/commonvoice/train.csv\"\n",
    "singlespeaker = \"data/singlespeaker/train.csv\"\n",
    "speechcollector = \"data/speechcollector/train.csv\"\n",
    "voxpopuli = \"data/fi/train.csv\"\n",
    "\n",
    "test = \"data/commonvoice/test.csv\"\n",
    "\n",
    "train_df = pd.concat([pd.read_csv(commonvoice), pd.read_csv(singlespeaker), pd.read_csv(speechcollector), pd.read_csv(voxpopuli)])\n",
    "test_df = pd.read_csv(test)\n",
    "\n",
    "print(f\"Training set contains {len(train_df)} Samples\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab259fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>mitä nyt tekisimme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>äänestämme tämän vuoksi toisin kuin maataloude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>rupeatko remmiin vai et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>äänestin näin ollen mietinnön puolesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/sampo/.cache/huggingface/datasets/downlo...</td>\n",
       "      <td>kiitos että tulitte ja opetitte meille viisaut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "1  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "2  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "3  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "4  /home/sampo/.cache/huggingface/datasets/downlo...   \n",
       "\n",
       "                                            sentence  \n",
       "0                                mitä nyt tekisimme   \n",
       "1  äänestämme tämän vuoksi toisin kuin maataloude...  \n",
       "2                           rupeatko remmiin vai et   \n",
       "3            äänestin näin ollen mietinnön puolesta   \n",
       "4  kiitos että tulitte ja opetitte meille viisaut...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\'\\...\\…\\–\\é]'\n",
    "\n",
    "def custom_remove_special_characters(sent):\n",
    "    sent = re.sub(chars_to_ignore_regex, '', sent).lower() + \" \"\n",
    "    return sent\n",
    "\n",
    "train_df['sentence'] = train_df['sentence'].apply(custom_remove_special_characters)\n",
    "test_df['sentence'] = test_df['sentence'].apply(custom_remove_special_characters)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c175140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0, 'o': 1, 'v': 2, 'e': 3, 'k': 4, 'ö': 5, 'h': 6, 'm': 7, 'i': 8, 's': 9, ' ': 10, 't': 11, 'u': 12, 'l': 13, 'ä': 14, 'c': 15, 'a': 16, 'f': 17, 'r': 18, 'b': 19, 'd': 20, 'å': 21, 'q': 22, 'p': 23, 'z': 24, 'g': 25, 'j': 26, 'w': 27, 'y': 28, 'n': 29}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def get_chars(df):\n",
    "    return set(itertools.chain(*[list(x) for x in df['sentence'].values]))\n",
    "\n",
    "vocab_list = list(get_chars(train_df).union(get_chars(test_df)))\n",
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ddaaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]\n",
    "\n",
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "\n",
    "#for key in vocab_dict.keys():\n",
    "#    if key != \"[PAD]\":\n",
    "#        vocab_dict[key] +=1\n",
    "\n",
    "import json\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e081cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c2a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import librosa\n",
    "\n",
    "def resample(audio, source_sr, target_sr = 16000):\n",
    "    audio = librosa.resample(np.asarray(audio), source_sr, target_sr)\n",
    "    return audio\n",
    "\n",
    "class CTCDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class used for Speech recognition with ctc loss\n",
    "    enables precomputing data as arrays or transforming on the fly\n",
    "    if dataset does not fit into ram\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, processor, mode=\"otf\"):\n",
    "        \n",
    "        self.data = dataframe\n",
    "        self.data.sort_values(by=\"sentence\", key=lambda x: x.str.len(), inplace=True, ascending=False)\n",
    "        self.processor = processor\n",
    "        self.mode = mode\n",
    "        if mode!=\"otf\":\n",
    "            raise NotImplemented\n",
    "    \n",
    "    def _processaudio(self, path):\n",
    "        data, sr = torchaudio.load(path)\n",
    "        data = data[0].numpy()\n",
    "        data = resample(data, sr, 16000)\n",
    "        \n",
    "        return data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):     \n",
    "        if self.mode == 'otf':\n",
    "            sent = self.data.iloc[idx, 1]\n",
    "            data = self._processaudio(self.data.iloc[idx, 0])\n",
    "            return data, sent\n",
    "        \n",
    "    def _precompute(self):\n",
    "        pass\n",
    "    \n",
    "    def reorder_df(self):\n",
    "        pass\n",
    "    \n",
    "def collate_fn_otf(batch):\n",
    "    \"\"\"\n",
    "    collate function used for training and loading audio data on the fly\n",
    "    \"\"\"\n",
    "    \n",
    "    lists = list(zip(*batch))\n",
    "    inputs = processor(lists[0], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "    with processor.as_target_processor():\n",
    "        labels = processor(lists[1], padding=True, return_tensors=\"pt\").input_ids\n",
    "    return inputs.input_values, inputs.attention_mask, labels\n",
    "\n",
    "trainset = CTCDataset(train_df, processor)\n",
    "testset = CTCDataset(test_df, processor)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = 4, collate_fn = collate_fn_otf, num_workers=4)\n",
    "testloader = DataLoader(testset, batch_size=1, collate_fn = collate_fn_otf, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f8745",
   "metadata": {},
   "source": [
    "# Make Lightning DataModule"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5846ddc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "class CTCDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    DataModule to handle setting up dataloaders\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, train_dr, valid_df, processor, batch_size=4, num_workers=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.valid_df  = valid_df\n",
    "        \n",
    "        self.processor = processor\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    def setup(self, stage):\n",
    "        self.trainset = CTCDataset(self.train_df, self.processor)\n",
    "        self.testset = CTCDataset(self.valid_df, self.processor)\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.trainset, batch_size = self.batch_size, collate_fn = collate_fn_otf, num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.testset, batch_size = 1, collate_fn = collate_fn_otf, num_workers=self.num_workers)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9d359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "def decode_output(logits):\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    pred = processor.batch_decode(pred_ids)\n",
    "    return pred[0]\n",
    "\n",
    "class Wav2Vec2Module(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, ref_sentences, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.model = Wav2Vec2ForCTC.from_pretrained(\n",
    "            \"facebook/wav2vec2-large-100k-voxpopuli\",\n",
    "            attention_dropout=0.1,\n",
    "            hidden_dropout=0.1,\n",
    "            feat_proj_dropout=0.0,\n",
    "            mask_time_prob=0.05,\n",
    "            layerdrop=0.1,\n",
    "            gradient_checkpointing=True,\n",
    "            ctc_loss_reduction=\"mean\",\n",
    "            pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            vocab_size=len(processor.tokenizer),\n",
    "            ctc_zero_infinity=False\n",
    "        )\n",
    "        self.model.train()\n",
    "        self.model.freeze_feature_extractor()\n",
    "        self.best_wer = 1.0\n",
    "        self.predictions = []\n",
    "        #model.to(device)\n",
    "        self.ref_sentences = ref_sentences\n",
    "        \n",
    "    def forward(self, inputs, masks, labels):\n",
    "        output = self.model(inputs, masks, labels=labels)\n",
    "        return output\n",
    "        \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        inputs, masks, labels = train_batch\n",
    "        loss = self(inputs, masks, labels)\n",
    "        return loss.loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        inputs, masks, labels = val_batch\n",
    "        output = self(inputs, masks, labels)\n",
    "        loss = output.loss.item()\n",
    "        pred = decode_output(output.logits)\n",
    "        self.predictions.append(pred)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        lr = 0.0002\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr)\n",
    "        scheduler = scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, \n",
    "                                   steps_per_epoch=int(len(trainloader)/2),\n",
    "                                   epochs = 30,\n",
    "                                   anneal_strategy='linear')\n",
    "        return [optimizer], [scheduler]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdb34a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-100k-voxpopuli and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type           | Params\n",
      "-----------------------------------------\n",
      "0 | model | Wav2Vec2ForCTC | 315 M \n",
      "-----------------------------------------\n",
      "311 M     Trainable params\n",
      "4.2 M     Non-trainable params\n",
      "315 M     Total params\n",
      "1,261.886 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254010702b5047eab79fc34b340fec0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "341    nykyiset rajoitustoimet ovat luonteeltaan pääa...\n",
      "220    marsia johtavalla niin kutsutulla demokraattis...\n",
      "285    silloin hänen pönkittynyt egonsa saisi hänet v...\n",
      "277    vanhasen pitkää pääministerikautta värittivät ...\n",
      "173    arkin keittäjät olivat ensimmäistä kertaa pääs...\n",
      "                             ...                        \n",
      "194                                         istuin alas \n",
      "20                                          no johan on \n",
      "157                                          hyvää yötä \n",
      "99                                           niin se on \n",
      "294                                            mitä nyt \n",
      "Name: sentence, Length: 428, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sampo/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sampo/anaconda3/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/sampo/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/sampo/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/sampo/anaconda3/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "from datasets import load_metric\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"wer\", dirpath=\"lightning_run\", filename=\"large_{wer:02f}\", save_top_k=1, mode=\"min\")\n",
    "    \n",
    "\n",
    "class EvalCallbacks(Callback):\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        wer = load_metric(\"wer\")\n",
    "        print(pl_module.predictions)\n",
    "        print(pl_module.ref_sentences)\n",
    "        wer_c = wer.compute(predictions=pl_module.predictions, references=pl_module.ref_sentences.to_list())\n",
    "        if wer_c < pl_module.best_wer:\n",
    "            pl_module.best_wer = wer_c\n",
    "            print(f\"new best wer: {wer_c}\")\n",
    "        pl_module.log(\"wer\", wer_c)\n",
    "        pl_module.predictions = []\n",
    "        \n",
    "        \n",
    "        \n",
    "m = Wav2Vec2Module(testset.data.sentence)\n",
    "trainer = pl.Trainer(callbacks=[checkpoint_callback, EvalCallbacks()], accumulate_grad_batches=2, max_epochs=30, precision=16, gpus=1, num_sanity_val_steps=0)\n",
    "trainer.fit(m, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d3c7781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer = load_metric(\"wer\")\n",
    "wer.compute(predictions=[\"moi\", \"hei\"], references=[\"moi\", \"hei\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
